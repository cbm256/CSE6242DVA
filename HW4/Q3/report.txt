Section A
1. Random Forest
weka.classifiers.trees.RandomForest -P 100 -I 100 -num-slots 1 -K 0 -M 1.0 -V 0.001 -S 1
Time taken to build model: 0.1 seconds
Overall accuracy: 86.6769 %
Confusion Matrix:
   a   b   <-- classified as
 316  41 |   a = 0
  46 250 |   b = 1

2. Logistic Regression
weka.classifiers.functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4
Time taken to build model: 0.11 seconds
Overall accuracy: 86.3706 %
Confusion Matrix:
   a   b   <-- classified as
 302  55 |   a = 0
  34 262 |   b = 1

3. Multi-layer Perceptron
weka.classifiers.functions.MultilayerPerceptron -L 0.3 -M 0.2 -N 500 -V 0 -S 0 -E 20 -H a
Time taken to build model: 5.17 seconds
Overall accuracy: 83.3078 %
Confusion Matrix:
   a   b   <-- classified as
 298  59 |   a = 0
  50 246 |   b = 1

4. SVM
weka.classifiers.functions.SGD -F 0 -L 0.01 -R 1.0E-4 -E 500 -C 0.001 -S 1
Time taken to build model: 0.07 seconds
Overall accuracy: 85.9112 %
Confusion Matrix:
   a   b   <-- classified as
 286  71 |   a = 0
  21 275 |   b = 1

5. Bayes Net
weka.classifiers.bayes.BayesNet -D -Q weka.classifiers.bayes.net.search.local.K2 -- -P 1 -S BAYES -E weka.classifiers.bayes.net.estimate.SimpleEstimator -- -A 0.5
Time taken to build model: 0.01 seconds
Overall accuracy: 85.9112 %
Confusion Matrix:
   a   b   <-- classified as
 321  36 |   a = 0
  56 240 |   b = 1

Section B
1.
  a.
    I modified the batch size of random trees from 100 to 10.
    Runtime decreased to 0.06 seconds.
    It was because the number of trees we have to train decreased and actually the trees training process is really time costly.
  b.
    I modified the batch size of logistic regression from 100 to 10.
    Runtime decreased to 0.04 seconds.
    It was because the number of logistic regression models we have to train decreased and actually the training process is really time costly.
  c.
    I modified the learning rate of Multi-layer Perceptron from 0.3 to 0.1.
    Runtime increased to 5.37 seconds and the overall accuracy increased to 84.0735%.
    It was because the learning rate determines the coverage rate of Multi-layer Perceptron algorithm. And while it coverages slowly the jump interval decreases and prediction accuracy increases.
  d.
    I modified the learning rate of SVM from 0.01 to 0.1.
    Runtime decreased to 0.04 seconds.
    It was because the learning rate determines the coverage rate of SVM algorithm. And while the learning rate increases the algorithm coverges faster.
  e.
    I modified the type of estimator from SimpleEstimator to BMAEstimator.
    Overall accuracy decreased to 84.5329%.
    It was because the SimpleEstimator has better performance than BMAEstimator on this dataset.

2. The result of my implementation was 85.30%, compared to Weka's 86.6769%. It was because my implementation doesn't use 10 fold cross validation. Also, Weka has some parameters such as max-depth control, numeriteration and batchsize, which determine the convergency speed and accuracy but the values are different from mine. 

3. In terms of running time, accuracy and confusion matrix, the best performing approach is Random Forest. Obviously Multi-layer Perceptron is the worst because it has low accuracy as well as costs more time. For SVM and Bayes Net, both of them cost less time than Random Forest but with less accuracy. Logistic Regression has almost similiar performance as Random Forest. But looking at the confusion matrix, Random Forest has more examples which are classified correctly.
